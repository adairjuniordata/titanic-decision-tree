# ğŸŒŠ Titanic - PrediÃ§Ã£o com Ãrvore de DecisÃ£o ğŸŒ³

Este repositÃ³rio apresenta um modelo de **Machine Learning** baseado em **Ãrvores de DecisÃ£o** para prever a sobrevivÃªncia dos passageiros do Titanic.

---

[![Abrir no Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Lu96iCZDE_aRB3Kx5hwLdoHyPShYnueq#scrollTo=cfe51bca)


## ğŸ“Œ VisÃ£o Geral
Este projeto realiza:

### ğŸ“Š **PreparaÃ§Ã£o dos Dados**
âœ” Carregamento do conjunto de dados do Titanic ğŸ“‚  
âœ” Tratamento de valores ausentes  
âœ” ConversÃ£o de variÃ¡veis categÃ³ricas para formato numÃ©rico ğŸ”„  
âœ” SeleÃ§Ã£o das features mais relevantes para a previsÃ£o ğŸ¯  
âœ” DivisÃ£o dos dados em conjunto de treino (80%) e teste (20%) ğŸ“š  

### ğŸ‹ï¸ **Treinamento do Modelo**
âœ” ConstruÃ§Ã£o de uma Ã¡rvore de decisÃ£o com `max_depth=20` ğŸŒ³  
âœ” Ajuste do modelo com os dados de treino ğŸ“‰  
âœ” CÃ¡lculo da acurÃ¡cia nos dados de treino ğŸ¯  

### ğŸ“ˆ **ValidaÃ§Ã£o e Teste**
âœ” AvaliaÃ§Ã£o do modelo com dados de teste ğŸ“Š  
âœ” PrevisÃ£o da sobrevivÃªncia dos passageiros de teste ğŸš¢  
âœ” Medida de desempenho usando `accuracy_score` ğŸ“  

### ğŸŒ² **VisualizaÃ§Ã£o da Ãrvore de DecisÃ£o**
âœ” Gera e exibe um grÃ¡fico representando a estrutura da Ã¡rvore ğŸŒ¿  

---

## ğŸ›  Tecnologias Utilizadas
- **Python** ğŸ
- **Pandas** ğŸ“Š
- **Scikit-Learn** ğŸ¤–
- **Matplotlib** ğŸ“‰
- **Seaborn** ğŸ¨

---

## ğŸš€ Como Executar

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/adairjuniordata/titanic-decision-tree.git
   ```

2. **Instale as dependÃªncias**:
   ```bash
   pip install pandas scikit-learn matplotlib seaborn
   ```

3. **Execute o script**:
   ```bash
   python titanic_decision.py
   ```

---

## ğŸ“Œ Resumo do Modelo  
ğŸ“Œ AcurÃ¡cia no teste: **82.02%**  
 

## ğŸ” Melhorias Futuras
ğŸ”¹ Ajustar hiperparÃ¢metros (`min_samples_split`, `min_samples_leaf`) para reduzir overfitting.  
ğŸ”¹ Explorar outros algoritmos, como **Random Forest** ou **XGBoost**, para possÃ­vel ganho de desempenho.  

---

